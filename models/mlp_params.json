{"activation": "relu", "alpha": 0.0001, "hidden_layer_sizes": [60, 30, 30], "learning_rate_init": 0.001, "max_iter": 500, "solver": "adam"}